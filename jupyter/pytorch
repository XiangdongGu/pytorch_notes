{"cells":[{"source":["import torch\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### 3.1 Tensors Fundamentals\n"," - *torch.ones* and *torch.zeros* are used to create vector of 1 or 0\n"," - *torch.tensor* is used to create from a numeric list\n"," - Use [] to extract/assign element in a tensor by index"],"metadata":{}},{"cell_type":"markdown","source":[" ### 3.3 Tensors and Storages\n"," - The storage underhood of tensor is a contiguous array\n"," - Stride is a tuple indicating the nubmer of elements in the storage taht have to be skipped when index is increased by 1 in each dimension\n"," - Accessing an element i, j: storage_offset + stride[0] * i + stride[1] * j\n"," - Changing sub-tensor will have side-effect on the original tensor, so we can clone the sub-tensor\n"," - Transpose of tensor have same storage but different stride, and not contiguous\n"," - We can obtain a new contiguous tensor from a non-contiguous tensor using contiguous method"],"metadata":{}},{"source":["points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n","points.storage()\n","\n","second_point = points[1]\n","second_point.storage_offset()\n","second_point.size()\n","second_point.shape\n","\n","points.stride()\n","\n","second_point = points[1].clone()\n","second_point[0] = 10.0\n","\n","points_t = points.t() # transpose the tensor\n","id(points.storage()) == id(points_t.storage()) # they have same storage\n","points_t.stride() # stride is transposed\n","points_t.is_contiguous()\n","\n","points_t_cont = points_t.contiguous()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Numeric Types\n"," - torch.float32/torch.float, torch.float64/torch.double, torch.float16, torch.int8, torch.unint8, torch.int16, torch.int32, torch.int64\n"," - Specify numeric type using dtype argument\n"," - Specify numeric type using casting method"],"metadata":{}},{"source":["double_points = torch.ones(10, 2, dtype = torch.double)\n","short_points = torch.tensor([[1, 2], [3, 4]], dtype = torch.short)\n","\n","double_points = torch.ones(10, 2).to(torch.double)\n","short_points = torch.tensor([[1, 2], [3, 4]]).to(torch.short)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### 3.5 Indexing tensors\n"," - some_list[:] all members in the list\n"," - some_list[1:4] from element 1 inclusive to element 4 exclusive\n"," - some_list[1:] from element 1 inclusive to the end of the list\n"," - some_list[:4] from the start of the list to element 4 exclusive\n"," - some_list[:-1] from the start of the list to one before the last element\n"," - some_list[1:4:2] from element 1 inclusive to element 4 exclusive in steps of 2"],"metadata":{}},{"cell_type":"markdown","source":[" ### Numpy interoperability"],"metadata":{}},{"source":["points = torch.ones(3, 4)\n","points_np = points.numpy()\n","points_np\n","\n","points1 = torch.from_numpy(points_np)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### The tensor API\n"," - creation ops: ones, zeros, from_numpy\n"," - Indexing, slicing, joining, mutating ops: transpose\n"," - Math ops\n"," - Random sampling: randn, normal\n"," - Serialization: load, save\n"," - Parallelism: set_num_threds"],"metadata":{}},{"cell_type":"markdown","source":[" ### Exercise"],"metadata":{}},{"source":["a = torch.tensor(range(9))\n","a.size()\n","a.storage_offset()\n","a.shape\n","\n","# ??? why\n","b = a.view(3, 3)\n","b[1, 1]\n","c = b[1:, 1:]\n","c.size()\n","c.storage_offset()\n","c.stride()\n","\n","torch.log(a.to(torch.float))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}